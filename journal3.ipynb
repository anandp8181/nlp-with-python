{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "journal3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gNry-61fnD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting all the links from the journal webpage in 'wiki' consisting all the volumes and issues and appending to href_list\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from urllib.parse import urlparse, urljoin\n",
        "href_list =[]\n",
        "url = \"https://link.springer.com\"\n",
        "wiki = \"https://link.springer.com/journal/42822/volumes-and-issues\"\n",
        "href_list = []\n",
        "#Query the website and return the html to the variable 'page'\n",
        "page = urllib.request.urlopen(wiki)\n",
        "soup = BeautifulSoup(page) \n",
        "for link in soup.find_all(\"a\", class_=\"u-interface-link u-text-sans-serif u-text-sm\"):\n",
        "  href = link['href']\n",
        "  href = urljoin(url, href)\n",
        "  href_list.append(href)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QSUxT9to2CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking whether for a link,next page exists or not if exists append that link also to href_list\n",
        "def no_of_pages(href_list):\n",
        "  set1  = set()\n",
        "  for i in href_list:\n",
        "    page = urllib.request.urlopen(i)\n",
        "    soup = BeautifulSoup(page) \n",
        "    for link in soup.find_all(\"a\", class_=\"next\"):\n",
        "      hreff = link['href']\n",
        "      hreff2 = url + hreff\n",
        "      set1.add(hreff2)\n",
        "  return set1\n",
        "\n",
        "list2 = []\n",
        "set1 = no_of_pages(href_list) \n",
        "while(len(set1)>0):\n",
        "  for value in set1:\n",
        "    list2.append(value)\n",
        "  set1 = no_of_pages(list2)\n",
        "for i in list2:\n",
        "  href_list.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce4uT0m52Wrk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf4WypmZDWtS",
        "colab_type": "code",
        "outputId": "574ac8eb-535a-4851-8e36-449d95aecced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "href_list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://link.springer.com/journal/40614/42/4',\n",
              " 'https://link.springer.com/journal/40614/42/3',\n",
              " 'https://link.springer.com/journal/40614/42/2',\n",
              " 'https://link.springer.com/journal/40614/42/1',\n",
              " 'https://link.springer.com/journal/40614/41/2',\n",
              " 'https://link.springer.com/journal/40614/41/1',\n",
              " 'https://link.springer.com/journal/40614/40/2',\n",
              " 'https://link.springer.com/journal/40614/40/1',\n",
              " 'https://link.springer.com/journal/40614/39/2',\n",
              " 'https://link.springer.com/journal/40614/39/1',\n",
              " 'https://link.springer.com/journal/40614/38/2',\n",
              " 'https://link.springer.com/journal/40614/38/1',\n",
              " 'https://link.springer.com/journal/40614/37/2',\n",
              " 'https://link.springer.com/journal/40614/37/1',\n",
              " 'https://link.springer.com/journal/40614/36/2',\n",
              " 'https://link.springer.com/journal/40614/36/1',\n",
              " 'https://link.springer.com/journal/40614/35/2',\n",
              " 'https://link.springer.com/journal/40614/35/1',\n",
              " 'https://link.springer.com/journal/40614/34/2',\n",
              " 'https://link.springer.com/journal/40614/34/1',\n",
              " 'https://link.springer.com/journal/40614/33/2',\n",
              " 'https://link.springer.com/journal/40614/33/1',\n",
              " 'https://link.springer.com/journal/40614/32/2',\n",
              " 'https://link.springer.com/journal/40614/32/1',\n",
              " 'https://link.springer.com/journal/40614/31/2',\n",
              " 'https://link.springer.com/journal/40614/31/1',\n",
              " 'https://link.springer.com/journal/40614/30/2',\n",
              " 'https://link.springer.com/journal/40614/30/1',\n",
              " 'https://link.springer.com/journal/40614/29/2',\n",
              " 'https://link.springer.com/journal/40614/29/1',\n",
              " 'https://link.springer.com/journal/40614/28/2',\n",
              " 'https://link.springer.com/journal/40614/28/1',\n",
              " 'https://link.springer.com/journal/40614/27/2',\n",
              " 'https://link.springer.com/journal/40614/27/1',\n",
              " 'https://link.springer.com/journal/40614/26/2',\n",
              " 'https://link.springer.com/journal/40614/26/1',\n",
              " 'https://link.springer.com/journal/40614/25/2',\n",
              " 'https://link.springer.com/journal/40614/25/1',\n",
              " 'https://link.springer.com/journal/40614/24/2',\n",
              " 'https://link.springer.com/journal/40614/24/1',\n",
              " 'https://link.springer.com/journal/40614/23/2',\n",
              " 'https://link.springer.com/journal/40614/23/1',\n",
              " 'https://link.springer.com/journal/40614/22/2',\n",
              " 'https://link.springer.com/journal/40614/22/1',\n",
              " 'https://link.springer.com/journal/40614/21/2',\n",
              " 'https://link.springer.com/journal/40614/21/1',\n",
              " 'https://link.springer.com/journal/40614/20/2',\n",
              " 'https://link.springer.com/journal/40614/20/1',\n",
              " 'https://link.springer.com/journal/40614/19/2',\n",
              " 'https://link.springer.com/journal/40614/19/1',\n",
              " 'https://link.springer.com/journal/40614/18/2',\n",
              " 'https://link.springer.com/journal/40614/18/1',\n",
              " 'https://link.springer.com/journal/40614/17/2',\n",
              " 'https://link.springer.com/journal/40614/17/1',\n",
              " 'https://link.springer.com/journal/40614/16/2',\n",
              " 'https://link.springer.com/journal/40614/16/1',\n",
              " 'https://link.springer.com/journal/40614/15/2',\n",
              " 'https://link.springer.com/journal/40614/15/1',\n",
              " 'https://link.springer.com/journal/40614/14/2',\n",
              " 'https://link.springer.com/journal/40614/14/1',\n",
              " 'https://link.springer.com/journal/40614/13/2',\n",
              " 'https://link.springer.com/journal/40614/13/1',\n",
              " 'https://link.springer.com/journal/40614/12/2',\n",
              " 'https://link.springer.com/journal/40614/12/1',\n",
              " 'https://link.springer.com/journal/40614/11/2',\n",
              " 'https://link.springer.com/journal/40614/11/1',\n",
              " 'https://link.springer.com/journal/40614/10/2',\n",
              " 'https://link.springer.com/journal/40614/10/1',\n",
              " 'https://link.springer.com/journal/40614/9/2',\n",
              " 'https://link.springer.com/journal/40614/9/1',\n",
              " 'https://link.springer.com/journal/40614/8/2',\n",
              " 'https://link.springer.com/journal/40614/8/1',\n",
              " 'https://link.springer.com/journal/40614/7/2',\n",
              " 'https://link.springer.com/journal/40614/7/1',\n",
              " 'https://link.springer.com/journal/40614/6/2',\n",
              " 'https://link.springer.com/journal/40614/6/1',\n",
              " 'https://link.springer.com/journal/40614/5/2',\n",
              " 'https://link.springer.com/journal/40614/5/1',\n",
              " 'https://link.springer.com/journal/40614/4/2',\n",
              " 'https://link.springer.com/journal/40614/4/1',\n",
              " 'https://link.springer.com/journal/40614/3/2',\n",
              " 'https://link.springer.com/journal/40614/3/1',\n",
              " 'https://link.springer.com/journal/40614/2/2',\n",
              " 'https://link.springer.com/journal/40614/2/1',\n",
              " 'https://link.springer.com/journal/40614/1/1',\n",
              " 'https://link.springer.com/journal/40614/16/2/page/2',\n",
              " 'https://link.springer.com/journal/40614/14/2/page/2',\n",
              " 'https://link.springer.com/journal/40614/9/2/page/2',\n",
              " 'https://link.springer.com/journal/40614/41/2/page/2',\n",
              " 'https://link.springer.com/journal/40614/10/1/page/2',\n",
              " 'https://link.springer.com/journal/40614/17/1/page/2',\n",
              " 'https://link.springer.com/journal/40614/40/1/page/2',\n",
              " 'https://link.springer.com/journal/40614/18/2/page/2',\n",
              " 'https://link.springer.com/journal/40614/12/2/page/2',\n",
              " 'https://link.springer.com/journal/40614/19/1/page/2',\n",
              " 'https://link.springer.com/journal/40614/10/2/page/2',\n",
              " 'https://link.springer.com/journal/40614/18/1/page/2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT5BNm_xj5-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now getting the article links from the journal links and appending all article links to href_list1\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from urllib.parse import urlparse, urljoin\n",
        "url = \"https://link.springer.com\"\n",
        "href_list1 = []\n",
        "href1 = ''\n",
        "k = 0 \n",
        "#Query the website and return the html to the variable 'page'\n",
        "for link in href_list:\n",
        "  k  = k + 1\n",
        "  page = urllib.request.urlopen(link)\n",
        "  soup = BeautifulSoup(page) \n",
        "  list = []\n",
        "  class1 = 'toc-item no-access'\n",
        "  class2 = 'toc-item'\n",
        "  \n",
        "  selects =soup.findAll(class_='webtrekk-track pdf-link')\n",
        "  selects1 =soup.findAll(class_ = 'webtrekk-track fulltext')\n",
        "  for match in selects:\n",
        "    match.decompose()\n",
        "  for match in selects1:\n",
        "    match.decompose()\n",
        "  \n",
        "  for x in soup.findAll(\"div\", attrs = {'class' : [class1,class2]}):\n",
        "    links = x.findAll('a')\n",
        "    for i in links:\n",
        "      if 'article' in i['href']:\n",
        "        if 'pdf' not in i['href']:\n",
        "          href1 = urljoin(url, i['href'])\n",
        "          href_list1.append(href1)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SR3GBpNPpYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now getting all the references from the article links and appending to the list2 \n",
        "import xlsxwriter\n",
        "from xlsxwriter import Workbook\n",
        "import os, glob,xlwt\n",
        "import time\n",
        "from socket import error as SocketError\n",
        "import errno\n",
        "import re\n",
        "wbk = Workbook('journal8.xlsx')\n",
        "sheet = wbk.add_worksheet('data')\n",
        "list2 = []\n",
        "count = 0\n",
        "comb = ''\n",
        "authorandYear = ''\n",
        "row = 0\n",
        "clean = re.compile('<.*?>')\n",
        "for url in href_list1:\n",
        "  try:\n",
        "    page = urllib.request.urlopen(url)\n",
        "    soup = BeautifulSoup(page)\n",
        "    seven_day=soup.find('div', {'id' : 'Bib1-section'})\n",
        "  except SocketError as e:\n",
        "    if e.errno != errno.ECONNRESET:\n",
        "        raise # Not error we are looking for\n",
        "    else:\n",
        "      pass # Handle error here.\n",
        "  if seven_day == None:\n",
        "    pass\n",
        "  else:\n",
        "    forecast_items = seven_day.find_all(class_=\"c-article-references__text\")\n",
        "    #print(forecast_items)\n",
        "    for i in forecast_items:\n",
        "      j = (i.contents)\n",
        "      count = 0\n",
        "      for k in range(0,len(j)):\n",
        "        if 'retreived' in str(k):\n",
        "          count+=1 \n",
        "      if count > 0:\n",
        "        for i in j:\n",
        "          i = re.sub(r'<.*?>', '', str(i),flags=re.MULTILINE)\n",
        "          i = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', str(i), flags=re.MULTILINE)\n",
        "          comb = comb + i\n",
        "      else:\n",
        "        i = re.sub(r'<.*?>', '', str(i),flags=re.MULTILINE)\n",
        "        comb = comb + i\n",
        "      #write or edit the cleaned reference below\n",
        "      comb1 = re.sub(r'^.*[(]\\d{4}.*?[)]\\.?','',str(comb))\n",
        "      journalandarticle = comb1.split('.',1)\n",
        "      #print(journalandarticle)\n",
        "      article = journalandarticle[0]\n",
        "      if len(journalandarticle) != 2 :\n",
        "        journal = ''\n",
        "      else:\n",
        "        journal = journalandarticle[1]\n",
        "        journal = re.sub(r',\\s?\\d.*','' ,journal)\n",
        "      authorandYear = re.findall(r'.*[(]\\d{4}.*?[)]',str(comb))\n",
        "      year = re.findall(r'\\d{4}',str(authorandYear))\n",
        "      if len(year)<1:\n",
        "        year = ''\n",
        "      else:\n",
        "        year = year[0]\n",
        "      if len(authorandYear)<1:\n",
        "        authorandYear = ''\n",
        "      else:\n",
        "        authorandYear = authorandYear[0]\n",
        "      author = re.sub(r'[(]\\d{4}.*?[)]','',authorandYear)\n",
        "      #print(author)\n",
        "      sheet.write(row,0,str(journal))\n",
        "      sheet.write(row,1,str(article))\n",
        "      sheet.write(row,2,str(year))\n",
        "      sheet.write(row,3,str(author))      \n",
        "      row+=1\n",
        "      comb = ''\n",
        "      print(row)\n",
        "wbk.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93D2FGUWVyF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}